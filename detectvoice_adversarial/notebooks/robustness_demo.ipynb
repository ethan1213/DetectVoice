{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DetectVoice Adversarial Suite - Robustness Demo\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. Loading a detector model\n",
    "2. Generating adversarial examples\n",
    "3. Evaluating robustness\n",
    "4. Visualizing results\n",
    "\n",
    "⚠️ **ETHICS NOTICE**: This demo is for DEFENSIVE research only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.models.cnn.detector import CNNDetector\n",
    "from src.attacks import FGSM, PGD\n",
    "from src.utils.audio import AudioFeatureExtractor\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detector model\n",
    "detector = CNNDetector(input_channels=1, num_classes=2, dropout=0.5)\n",
    "detector.eval()\n",
    "\n",
    "# NOTE: In practice, load trained weights here:\n",
    "# checkpoint = torch.load('path/to/checkpoint.pt')\n",
    "# detector.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in detector.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Dummy Data\n",
    "\n",
    "For demonstration, we'll use dummy spectrograms. \n",
    "In practice, use real audio data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy mel-spectrograms\n",
    "batch_size = 8\n",
    "freq_bins = 128\n",
    "time_bins = 94\n",
    "\n",
    "# Dummy inputs (random spectrograms)\n",
    "inputs = torch.randn(batch_size, freq_bins, time_bins)\n",
    "\n",
    "# Dummy labels (4 real, 4 fake)\n",
    "labels = torch.cat([torch.ones(4), torch.zeros(4)]).long()\n",
    "\n",
    "print(f\"Input shape: {inputs.shape}\")\n",
    "print(f\"Labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get clean predictions\n",
    "with torch.no_grad():\n",
    "    outputs = detector(inputs)\n",
    "    probs = torch.softmax(outputs, dim=1)\n",
    "    preds = outputs.argmax(dim=1)\n",
    "\n",
    "clean_accuracy = (preds == labels).float().mean().item()\n",
    "\n",
    "print(f\"Clean Accuracy: {clean_accuracy:.2%}\")\n",
    "print(f\"Predictions: {preds}\")\n",
    "print(f\"Ground Truth: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FGSM attack\n",
    "fgsm = FGSM(model=detector, epsilon=0.03)\n",
    "\n",
    "# Generate adversarial examples\n",
    "adv_inputs_fgsm, fgsm_metrics = fgsm.generate(inputs, labels)\n",
    "\n",
    "print(f\"FGSM Metrics:\")\n",
    "print(f\"  L2 Norm: {fgsm_metrics['l2_norm']:.4f}\")\n",
    "print(f\"  L-inf Norm: {fgsm_metrics['linf_norm']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on adversarial examples\n",
    "with torch.no_grad():\n",
    "    adv_outputs = detector(adv_inputs_fgsm)\n",
    "    adv_preds = adv_outputs.argmax(dim=1)\n",
    "\n",
    "fgsm_accuracy = (adv_preds == labels).float().mean().item()\n",
    "\n",
    "print(f\"FGSM Adversarial Accuracy: {fgsm_accuracy:.2%}\")\n",
    "print(f\"Robustness Drop: {clean_accuracy - fgsm_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PGD attack\n",
    "pgd = PGD(model=detector, epsilon=0.03, alpha=0.01, num_iter=10)\n",
    "\n",
    "# Generate adversarial examples\n",
    "adv_inputs_pgd, pgd_metrics = pgd.generate(inputs, labels)\n",
    "\n",
    "print(f\"PGD Metrics:\")\n",
    "print(f\"  L2 Norm: {pgd_metrics['l2_norm']:.4f}\")\n",
    "print(f\"  L-inf Norm: {pgd_metrics['linf_norm']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on adversarial examples\n",
    "with torch.no_grad():\n",
    "    adv_outputs = detector(adv_inputs_pgd)\n",
    "    adv_preds = adv_outputs.argmax(dim=1)\n",
    "\n",
    "pgd_accuracy = (adv_preds == labels).float().mean().item()\n",
    "\n",
    "print(f\"PGD Adversarial Accuracy: {pgd_accuracy:.2%}\")\n",
    "print(f\"Robustness Drop: {clean_accuracy - pgd_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clean vs adversarial spectrograms\n",
    "sample_idx = 0\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# Clean\n",
    "axes[0].imshow(inputs[sample_idx].numpy(), aspect='auto', origin='lower')\n",
    "axes[0].set_title('Clean Spectrogram')\n",
    "axes[0].set_xlabel('Time')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# FGSM\n",
    "axes[1].imshow(adv_inputs_fgsm[sample_idx].numpy(), aspect='auto', origin='lower')\n",
    "axes[1].set_title('FGSM Adversarial')\n",
    "axes[1].set_xlabel('Time')\n",
    "\n",
    "# PGD\n",
    "axes[2].imshow(adv_inputs_pgd[sample_idx].numpy(), aspect='auto', origin='lower')\n",
    "axes[2].set_title('PGD Adversarial')\n",
    "axes[2].set_xlabel('Time')\n",
    "\n",
    "# Perturbation (FGSM)\n",
    "perturbation = (adv_inputs_fgsm[sample_idx] - inputs[sample_idx]).numpy()\n",
    "axes[3].imshow(perturbation, aspect='auto', origin='lower', cmap='RdBu')\n",
    "axes[3].set_title('FGSM Perturbation')\n",
    "axes[3].set_xlabel('Time')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Robustness Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary plot\n",
    "attacks = ['Clean', 'FGSM', 'PGD']\n",
    "accuracies = [clean_accuracy, fgsm_accuracy, pgd_accuracy]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(attacks, accuracies, color=['green', 'orange', 'red'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Robustness Against Adversarial Attacks')\n",
    "plt.ylim([0, 1])\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{acc:.1%}',\n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. ✓ Loading a detector model\n",
    "2. ✓ Generating FGSM and PGD adversarial examples\n",
    "3. ✓ Evaluating model robustness\n",
    "4. ✓ Visualizing attacks and perturbations\n",
    "\n",
    "**Next Steps:**\n",
    "- Use real audio data\n",
    "- Train models with adversarial training\n",
    "- Evaluate with comprehensive robustness suite\n",
    "- Export models for deployment\n",
    "\n",
    "⚠️ **Remember**: Use this tool ethically and responsibly for defensive research only."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
