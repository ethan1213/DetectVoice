# DetectVoice
Grupo de IAs que identifican voces falsas

---

## ğŸš€ DetectVoice - Sistema de DetecciÃ³n de Deepfakes de Voz

DetectVoice es un sistema profesional de detecciÃ³n de deepfakes de audio basado en mÃºltiples modelos de deep learning. Incluye capacidades de entrenamiento, evaluaciÃ³n, exportaciÃ³n y robustez adversarial.

### ğŸ“‹ CaracterÃ­sticas Principales

- **MÃºltiples Modelos de DetecciÃ³n**: CNN, RNN, CRNN, Transformer
- **ExportaciÃ³n Multi-formato**: PyTorch (.pt), TorchScript (.ts), ONNX (.onnx)
- **CongelaciÃ³n de Modelos**: FunciÃ³n `freeze_model()` para deployment
- **MÃ©tricas AutomÃ¡ticas**: GeneraciÃ³n de grÃ¡ficos y reportes completos
- **MÃ³dulo Adversarial Opcional**: Testing de robustez (FGSM, PGD, C&W, DeepFool)
- **EvaluaciÃ³n Adversarial**: Reportes detallados de robustez

### ğŸ“‚ Estructura del Proyecto

```
DetectVoice/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/          # Modelos de detecciÃ³n (CNN, RNN, etc.)
â”‚   â”œâ”€â”€ training/        # Scripts de entrenamiento
â”‚   â”œâ”€â”€ evaluation/      # MÃ³dulos de evaluaciÃ³n
â”‚   â”œâ”€â”€ utils/           # Utilidades (audio, mÃ©tricas, export)
â”‚   â”œâ”€â”€ data/            # Data loaders
â”‚   â””â”€â”€ adversarial/     # MÃ³dulo adversarial OPCIONAL
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ plots/           # GrÃ¡ficos generados por modelo
â”‚   â””â”€â”€ adversarial/     # Reportes adversariales
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ pt/              # Checkpoints PyTorch
â”‚   â”œâ”€â”€ torchscript/     # Modelos TorchScript
â”‚   â””â”€â”€ onnx/            # Modelos ONNX
â”œâ”€â”€ datasets/            # Datasets de entrenamiento
â””â”€â”€ configs/             # Archivos de configuraciÃ³n
```

### ğŸ¯ Uso RÃ¡pido

#### Entrenamiento de Modelo

```python
from src.models.cnn_detector import CNNDetector
from src.utils.metrics import MetricsLogger

# Crear modelo
model = CNNDetector(input_channels=1, num_classes=2)

# Entrenar (tu cÃ³digo de entrenamiento existente)
# ...

# Generar mÃ©tricas automÃ¡ticamente
metrics_logger = MetricsLogger(model_name="CNN", save_dir="reports/plots")
metrics_logger.generate_all_plots(y_true, y_pred, y_scores, real_spec, fake_spec)
```

#### ExportaciÃ³n de Modelo

```python
# Congelar modelo para deployment
model.freeze()

# Exportar a todos los formatos
example_input = torch.randn(1, 128, 94)  # Ejemplo de input
paths = model.export_all(
    base_path="checkpoints",
    model_name="CNN_detector",
    example_input=example_input
)
# Genera: .pt, .ts, .onnx automÃ¡ticamente
```

#### EvaluaciÃ³n Adversarial (Opcional)

```python
from src.adversarial.adversarial_evaluator import AdversarialEvaluator

# Crear evaluador
evaluator = AdversarialEvaluator(
    model=model,
    model_name="CNN_detector",
    device='cuda'
)

# Evaluar robustez contra todos los ataques
results = evaluator.evaluate_all_attacks(test_loader)
# Genera reportes automÃ¡ticos en reports/adversarial/
```

#### Uso de Ataques Adversariales

```python
from src.adversarial.fgsm import fgsm_attack
from src.adversarial.pgd import PGD

# FGSM
adv_audio = fgsm_attack(model, waveform, label, epsilon=0.03)

# PGD
pgd = PGD(model, epsilon=0.03, alpha=0.01, num_iter=10)
adv_audio, metrics = pgd.generate(waveform, label)
```

---

## ğŸ“Š Datasets Recomendados

Los siguientes datasets pÃºblicos son recomendados para entrenar y evaluar DetectVoice:

### Datasets Principales

1. **ASVspoof 2019**
   Dataset estÃ¡ndar para detecciÃ³n de audio spoofing
   ğŸ”— https://www.asvspoof.org/index2019.html

2. **DSD-Corpus**
   Deepfake Speech Detection Corpus
   ğŸ”— https://zenodo.org/records/13788455

3. **LibriTTS**
   Multi-speaker English corpus
   ğŸ”— https://us.openslr.org/60/

4. **LibriTTS-R**
   Restored version of LibriTTS
   ğŸ”— https://www.openslr.org/141/

### Datasets Especializados

5. **AUDETER**
   Audio Deepfake Detection Dataset
   ğŸ”— https://arxiv.org/abs/2509.04345

6. **FoR Dataset**
   Fake or Real Dataset for Synthetic Speech Detection
   ğŸ”— https://cisaad.umbc.edu/for-fake-or-real-dataset-for-synthetic-speech-detection/

7. **DEEP-VOICE**
   Deepfake Voice Recognition Dataset
   ğŸ”— https://huggingface.co/datasets/DynamicSuperb/DeepFakeVoiceRecognition_DEEP-VOICE

8. **HAD (Half-Truth Audio Dataset)**
   Partially synthetic audio dataset
   ğŸ”— https://arxiv.org/abs/2104.03617

9. **ELAD-SVDSR**
   Enhanced Dataset for Synthetic Voice Detection
   ğŸ”— https://arxiv.org/abs/2510.00218

---

## ğŸ¨ MÃ©tricas y GrÃ¡ficos Generados AutomÃ¡ticamente

Cada entrenamiento genera automÃ¡ticamente:

- âœ… **Curva de PÃ©rdida** (loss_curve.png)
- âœ… **Curva de Accuracy** (accuracy_curve.png)
- âœ… **Curva ROC** (roc_curve.png)
- âœ… **Curva Precision-Recall** (precision_recall_curve.png)
- âœ… **Matriz de ConfusiÃ³n** (confusion_matrix.png)
- âœ… **ComparaciÃ³n Real vs Fake** (spectrogram_comparison.png)
- âœ… **Reporte de ClasificaciÃ³n** (classification_report.txt)
- âœ… **MÃ©tricas JSON** (metrics.json)

Todos los archivos se guardan en: `reports/plots/[modelo]/`

---

## ğŸ”¬ Mejoras del Sistema v2

### Nuevas Funcionalidades

1. **Sistema de ExportaciÃ³n Completo**
   - ExportaciÃ³n a PyTorch, TorchScript y ONNX
   - FunciÃ³n `freeze_model()` para deployment
   - ValidaciÃ³n automÃ¡tica de modelos exportados

2. **GeneraciÃ³n AutomÃ¡tica de MÃ©tricas**
   - 6 tipos de grÃ¡ficos generados automÃ¡ticamente
   - Reportes en JSON y texto
   - Comparaciones visuales de espectrogramas

3. **MÃ³dulo Adversarial Opcional**
   - Ataques: FGSM, PGD, C&W, DeepFool
   - No interfiere con entrenamiento regular
   - EvaluaciÃ³n de robustez completa

4. **Evaluador Adversarial**
   - Prueba automÃ¡tica de todos los ataques
   - Reportes detallados con grÃ¡ficos
   - ComparaciÃ³n de accuracy clean vs adversarial

5. **Compatibilidad Mejorada**
   - IntegraciÃ³n con cÃ³digo existente
   - Sin cambios en flujo de entrenamiento
   - Funciones opcionales y modulares

### Mejoras de CÃ³digo

- âœ… Tipado completo con type hints
- âœ… Logging profesional
- âœ… DocumentaciÃ³n completa
- âœ… Estructura modular y extensible
- âœ… Compatible con GPU/CPU

---

## âš ï¸ Disclaimer Legal y Ã‰tico

**Este proyecto tiene fines exclusivamente acadÃ©micos, cientÃ­ficos y de ciberseguridad defensiva.**

NingÃºn componente del repositorio debe utilizarse para generar deepfakes o para actividades que involucren suplantaciÃ³n, ingenierÃ­a social o prÃ¡cticas maliciosas.

**El uso indebido de este software es responsabilidad Ãºnica del usuario.**

### Usos Permitidos
- âœ… InvestigaciÃ³n acadÃ©mica en detecciÃ³n de deepfakes
- âœ… Desarrollo de sistemas de seguridad defensivos
- âœ… Pruebas de robustez de modelos
- âœ… AnÃ¡lisis forense de audio

### Usos Prohibidos
- âŒ GeneraciÃ³n de deepfakes maliciosos
- âŒ SuplantaciÃ³n de identidad
- âŒ Fraude o engaÃ±o
- âŒ ViolaciÃ³n de privacidad
- âŒ Cualquier uso ilegal o no Ã©tico

**Al usar este software, acepta cumplir con todas las leyes aplicables y utilizarlo Ãºnicamente para fines legÃ­timos y Ã©ticos.**

---

## ğŸ“¦ InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/ethan1213/DetectVoice.git
cd DetectVoice

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

- Python 3.8+
- PyTorch >= 1.10
- TorchAudio
- NumPy, SciPy
- Matplotlib, Seaborn
- scikit-learn
- ONNX (para exportaciÃ³n)

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas siguiendo estos principios:

1. Enfoque en detecciÃ³n y seguridad defensiva
2. CÃ³digo bien documentado y testeado
3. Respeto a principios Ã©ticos
4. Compatibilidad con sistema existente

---

## ğŸ“ Licencia

Este proyecto estÃ¡ disponible para fines de investigaciÃ³n y educaciÃ³n. Ver LICENSE para mÃ¡s detalles.

---

## ğŸ“§ Contacto

Para preguntas sobre uso responsable o colaboraciones de investigaciÃ³n, abrir un issue en GitHub.

---

**Desarrollado con el objetivo de mejorar la seguridad y autenticidad del audio digital.**

**Uso responsable y Ã©tico Ãºnicamente. ğŸ”’**
# DetectVoice Adversarial Suite

**Professional Audio Deepfake Detection with Adversarial Robustness**

---

## âš ï¸ CRITICAL SECURITY AND ETHICS NOTICE

### Purpose and Intended Use

This project is designed **EXCLUSIVELY for DEFENSIVE purposes**:

âœ… **PERMITTED USES:**
- Academic research on deepfake detection
- Testing and improving detector robustness
- Security auditing and forensic analysis
- Training robust deepfake detection systems
- Defensive machine learning research

âŒ **PROHIBITED USES:**
- Creating realistic audio deepfakes
- Unauthorized voice cloning or impersonation
- Malicious synthesis or deception
- Bypassing security systems
- Any illegal or unethical applications

### Legal and Ethical Responsibilities

**BY USING THIS CODE, YOU AGREE TO:**

1. **Use Responsibly**: Only use for legitimate defensive research and security purposes
2. **Comply with Laws**: Follow all applicable local, state, and federal laws
3. **Respect Privacy**: Obtain proper consent before processing voice data
4. **No Malicious Use**: Never use for creating undetectable deepfakes or impersonation
5. **Attribution**: Cite this work appropriately in academic research

**DISCLAIMER**: The authors and contributors are NOT responsible for misuse of this software. Users bear full legal and ethical responsibility for their actions.

### Toy Generator Limitations

The included "toy generator" is **INTENTIONALLY LIMITED**:
- Produces LOW-FIDELITY audio unsuitable for realistic synthesis
- Designed ONLY for testing discriminators
- NOT capable of high-quality voice cloning
- Includes obvious artifacts for detection

This is NOT a production TTS system and should not be used as such.

---

## ğŸ¯ Project Overview

DetectVoice Adversarial Suite is a comprehensive framework for training, evaluating, and deploying robust audio deepfake detectors. It includes:

- **Multiple Detection Models**: CNN, RNN, CRNN, Transformer, Autoencoder, Siamese
- **Adversarial Robustness**: FGSM, PGD, C&W, DeepFool attacks
- **GAN Discriminators**: For forensic analysis
- **Ensemble Detection**: With explainability
- **Comprehensive Evaluation**: Metrics, plots, and reports
- **Model Export**: PyTorch, TorchScript, ONNX

---

## ğŸ“ Project Structure

```
detectvoice_adversarial/
â”œâ”€â”€ data/                          # Data directory
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/                    # Detection models
â”‚   â”‚   â”œâ”€â”€ cnn/                   # CNN detector
â”‚   â”‚   â”œâ”€â”€ rnn/                   # RNN (LSTM/GRU) detector
â”‚   â”‚   â”œâ”€â”€ crnn/                  # CRNN detector
â”‚   â”‚   â”œâ”€â”€ transformer/           # Transformer detector
â”‚   â”‚   â”œâ”€â”€ autoencoder/           # Autoencoder detector
â”‚   â”‚   â”œâ”€â”€ siamese/               # Siamese network
â”‚   â”‚   â”œâ”€â”€ discriminator/         # GAN discriminators (forensics)
â”‚   â”‚   â”œâ”€â”€ toy_generator/         # Low-fidelity toy generator (testing only)
â”‚   â”‚   â””â”€â”€ ensemble/              # Ensemble detector
â”‚   â”œâ”€â”€ attacks/                   # Adversarial attacks
â”‚   â”‚   â”œâ”€â”€ fgsm.py               # Fast Gradient Sign Method
â”‚   â”‚   â”œâ”€â”€ pgd.py                # Projected Gradient Descent
â”‚   â”‚   â”œâ”€â”€ cw.py                 # Carlini & Wagner
â”‚   â”‚   â”œâ”€â”€ deepfool.py           # DeepFool
â”‚   â”‚   â””â”€â”€ spec_perturbations.py # Spectral/temporal perturbations
â”‚   â”œâ”€â”€ training/                  # Training scripts
â”‚   â”‚   â”œâ”€â”€ train_cnn.py
â”‚   â”‚   â””â”€â”€ adv_train.py          # Adversarial training
â”‚   â”œâ”€â”€ evaluation/                # Evaluation suite
â”‚   â”‚   â””â”€â”€ robustness_eval.py    # Robustness evaluation
â”‚   â”œâ”€â”€ export/                    # Model export utilities
â”‚   â”‚   â””â”€â”€ export_utils.py       # PT, TorchScript, ONNX export
â”‚   â”œâ”€â”€ utils/                     # Utilities
â”‚   â”‚   â”œâ”€â”€ audio.py              # Audio processing
â”‚   â”‚   â”œâ”€â”€ dataloader.py         # Dataset loaders
â”‚   â”‚   â”œâ”€â”€ config.py             # Config management
â”‚   â”‚   â””â”€â”€ logger.py             # Logging
â”‚   â””â”€â”€ config/                    # Configuration files
â”‚       â””â”€â”€ cnn_config.yaml
â”œâ”€â”€ artifacts/                     # Output directory
â”‚   â”œâ”€â”€ models/                    # Saved models
â”‚   â”œâ”€â”€ metrics/                   # Metrics and reports
â”‚   â”œâ”€â”€ plots/                     # Visualizations
â”‚   â””â”€â”€ adversarial_examples/      # Adversarial samples
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”œâ”€â”€ tests/                         # Unit tests
â”œâ”€â”€ requirements.txt               # Dependencies
â””â”€â”€ README.md                      # This file
```

---

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/yourusername/detectvoice_adversarial.git
cd detectvoice_adversarial

# Create virtual environment
python3.10 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Prepare Data

Organize your audio data:

```
data/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ real/
â”‚   â”‚   â”œâ”€â”€ audio1.wav
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ fake/
â”‚       â”œâ”€â”€ audio1.wav
â”‚       â””â”€â”€ ...
â””â”€â”€ val/
    â”œâ”€â”€ real/
    â””â”€â”€ fake/
```

### Train a Detector

```bash
# Train CNN detector with adversarial training
python src/training/train_cnn.py --config src/config/cnn_config.yaml
```

### Evaluate Robustness

```python
from src.evaluation.robustness_eval import RobustnessEvaluator
from src.models.cnn.detector import CNNDetector

# Load model
model = CNNDetector()
# ... load checkpoint ...

# Evaluate
evaluator = RobustnessEvaluator(model, device='cuda')
results = evaluator.evaluate_comprehensive(test_loader)
```

---

## ğŸ“Š Adversarial Attacks

### Implemented Attacks

1. **FGSM** (Fast Gradient Sign Method)
   - Fast single-step attack
   - Epsilon parameter controls perturbation magnitude

2. **PGD** (Projected Gradient Descent)
   - Iterative version of FGSM
   - Stronger and more effective

3. **C&W** (Carlini & Wagner)
   - Optimization-based attack
   - Minimizes L2 perturbation

4. **DeepFool**
   - Finds minimal perturbation to decision boundary
   - Geometry-based approach

5. **Spectral Perturbations**
   - Audio-specific attacks
   - Time warping, frequency masking

### Example Usage

```python
from src.attacks import FGSM, PGD

# FGSM attack
fgsm = FGSM(model=detector, epsilon=0.03)
adv_examples, metrics = fgsm.generate(inputs, labels)

# PGD attack
pgd = PGD(model=detector, epsilon=0.03, alpha=0.01, num_iter=10)
adv_examples, metrics = pgd.generate(inputs, labels)
```

---

## ğŸ›¡ï¸ Adversarial Training

Train robust models using adversarial examples:

```python
from src.training.adv_train import AdversarialTrainer

trainer = AdversarialTrainer(
    model=model,
    optimizer=optimizer,
    adv_ratio=0.5,  # 50% adversarial examples
    attack_type='pgd',
    attack_params={'epsilon': 0.03, 'alpha': 0.01, 'num_iter': 7}
)

history = trainer.train(train_loader, val_loader, num_epochs=50)
```

---

## ğŸ“¦ Model Export

Export models to multiple formats:

```python
from src.export.export_utils import ModelExporter

exporter = ModelExporter(save_dir='artifacts/models', model_name='CNN_Detector')

# Export to all formats
export_paths = exporter.export_all(
    model=model,
    example_input=example_tensor,
    optimizer=optimizer,
    metrics=metrics
)

# Exports:
# - model.pt (PyTorch checkpoint)
# - model_frozen.pt (Frozen model)
# - model.ts (TorchScript)
# - model.onnx (ONNX)
```

---

## ğŸ¯ Ensemble Detection

Combine multiple models for robust detection:

```python
from src.models.ensemble.ensemble import EnsembleDetector

ensemble = EnsembleDetector(
    models=[cnn_detector, rnn_detector, transformer_detector],
    weights=[0.4, 0.3, 0.3],
    voting='soft'
)

# Predict with explanation
result = ensemble.predict_with_explanation(input_audio)
print(result['prediction'])
print(result['confidence'])
print(result['explanation'])
```

---

## ğŸ“ˆ Evaluation and Metrics

Comprehensive robustness evaluation:

- **Clean Accuracy**: Performance on unmodified samples
- **Adversarial Accuracy**: Performance on adversarial examples
- **Robustness Drop**: Difference between clean and adversarial accuracy
- **AUROC, Precision, Recall, F1**
- **Confusion Matrices**
- **ROC Curves**

All metrics are automatically saved to:
- `metrics.json`
- `metrics.csv`
- Visualization plots

---

## ğŸ§ª Testing

Run unit tests:

```bash
pytest tests/ -v
```

---

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
@software{detectvoice_adversarial,
  title={DetectVoice Adversarial Suite: Robust Audio Deepfake Detection},
  author={Your Name},
  year={2025},
  url={https://github.com/yourusername/detectvoice_adversarial}
}
```

---

## ğŸ“„ License

This project is released under the MIT License with additional ethical use clauses.

**IMPORTANT**: Users must comply with all legal and ethical guidelines. Misuse for creating deepfakes or unauthorized voice cloning is strictly prohibited.

---

## ğŸ¤ Contributing

Contributions for defensive research are welcome! Please:

1. Ensure contributions align with defensive purposes
2. Include tests for new features
3. Follow the code style
4. Update documentation

---

## ğŸ“ Contact

For questions about responsible use or research collaborations:
- Email: your.email@example.com
- Issues: GitHub Issues

---

## ğŸ”’ Security Policy

If you discover a security vulnerability or potential misuse:

1. **DO NOT** open a public issue
2. Email directly to: security@example.com
3. Provide detailed information
4. Allow reasonable time for response

---

## âš–ï¸ Ethical Guidelines Summary

1. **Defensive Research Only**: This tool is for detection, not creation
2. **Consent Required**: Obtain consent for processing voice data
3. **Legal Compliance**: Follow all applicable laws
4. **No Malicious Use**: Never use for unauthorized impersonation
5. **Transparency**: Disclose limitations and capabilities honestly

**Remember**: With great power comes great responsibility. Use this tool ethically and legally.

---
## ğŸ“š Datasets Utilizados (Voz Real, SintÃ©tica y Deepfake)

Este proyecto utiliza y recomienda mÃºltiples datasets de voz real y sintetizada para entrenar y evaluar modelos de detecciÃ³n de deepfakes. AquÃ­ estÃ¡n los enlaces oficiales y las referencias mencionadas previamente:

---

### ğŸ”¹ ASVspoof 2019 â€” Real + SintÃ©tica (TTS, VC, Replay)
Dataset clÃ¡sico y base de investigaciÃ³n para detecciÃ³n de audio falsificado.

- Sitio oficial: https://www.asvspoof.org/index2019.html
- Info completa: https://cisaad.umbc.edu/asvspoof-2019-a-large-scale-public-database-of-synthesized-converted-and-replayed-speech/
- MOS / Listening tests: https://zenodo.org/records/8412617

---

### ğŸ”¹ DSD-Corpus â€” Diverse Synthesizer for Deepfake Voice Detection
Dataset moderno de voces reales y sintetizadas por mÃºltiples TTS.

- Descarga: https://zenodo.org/records/13788455

---

### ğŸ”¹ LibriTTS â€” Voces Reales (Multi-Speaker)
Corpus ampliamente usado para TTS y como base de voces reales.

- LibriTTS (SLR60): https://us.openslr.org/60/
- LibriTTS-R (restaurado â€“ SLR141): https://www.openslr.org/141/
- InformaciÃ³n extra: https://korshakov.com/datasets/libritts-r

---

### ğŸ”¹ AUDETER â€” Deepfake Audio Detection Dataset (Alta Realidad)
Dataset de gran escala con sintetizadores modernos (2024â€“2025).

- Paper: https://arxiv.org/abs/2509.04345

---

### ğŸ”¹ Recursos Adicionales (Reales + SintÃ©ticos)
Estos datasets tambiÃ©n fueron mencionados previamente y son Ãºtiles para robustez y testing:

#### FoR: Fake-or-Real Speech Dataset
- Info: https://cisaad.umbc.edu/for-fake-or-real-dataset-for-synthetic-speech-detection/

#### DEEP-VOICE Dataset (Voice Conversion / Deepfake Recognition)
- HuggingFace: https://huggingface.co/datasets/DynamicSuperb/DeepFakeVoiceRecognition_DEEP-VOICE

#### Half-Truth HAD Dataset (Audio parcialmente sintetizado)
- Paper / Info: https://arxiv.org/abs/2104.03617

#### ELAD-SVDSR Dataset (Long recordings + deepfake)
- Info: https://arxiv.org/abs/2510.00218

---

### âœ” RecomendaciÃ³n de uso
Para mÃ¡xima robustez del sistema *DetectVoice*, utilizar combinaciones de:

- **Real:** LibriTTS, LibriTTS-R  
- **SintÃ©tica:** DSD-Corpus, FoR, DEEP-VOICE  
- **Adversarial / Deepfake:** ASVspoof 2019/2021, AUDETER, HAD  
- **Larga duraciÃ³n:** ELAD-SVDSR  

Estas bases cubren **TTS de baja calidad â†’ alta calidad**, **Voice Conversion**, **deepfakes de Ãºltima generaciÃ³n**, **audios adversariales**, y **grabaciones reales**.


---
Â© 2025 DetectVoice Adversarial Suite. All rights reserved.
