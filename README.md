# DetectVoice
Grupo de IAs que identifican voces falsas

---

## ğŸš€ DetectVoice - Sistema de DetecciÃ³n de Deepfakes de Voz

DetectVoice es un sistema profesional de detecciÃ³n de deepfakes de audio basado en mÃºltiples modelos de deep learning. Incluye capacidades de entrenamiento, evaluaciÃ³n, exportaciÃ³n y robustez adversarial.

### ğŸ“‹ CaracterÃ­sticas Principales

- **MÃºltiples Modelos de DetecciÃ³n**: CNN, RNN, CRNN, Transformer
- **ExportaciÃ³n Multi-formato**: PyTorch (.pt), TorchScript (.ts), ONNX (.onnx)
- **CongelaciÃ³n de Modelos**: FunciÃ³n `freeze_model()` para deployment
- **MÃ©tricas AutomÃ¡ticas**: GeneraciÃ³n de grÃ¡ficos y reportes completos
- **MÃ³dulo Adversarial Opcional**: Testing de robustez (FGSM, PGD, C&W, DeepFool)
- **EvaluaciÃ³n Adversarial**: Reportes detallados de robustez

### ğŸ“‚ Estructura del Proyecto

```
DetectVoice/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/          # Modelos de detecciÃ³n (CNN, RNN, etc.)
â”‚   â”œâ”€â”€ training/        # Scripts de entrenamiento
â”‚   â”œâ”€â”€ evaluation/      # MÃ³dulos de evaluaciÃ³n
â”‚   â”œâ”€â”€ utils/           # Utilidades (audio, mÃ©tricas, export)
â”‚   â”œâ”€â”€ data/            # Data loaders
â”‚   â””â”€â”€ adversarial/     # MÃ³dulo adversarial OPCIONAL
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ plots/           # GrÃ¡ficos generados por modelo
â”‚   â””â”€â”€ adversarial/     # Reportes adversariales
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ pt/              # Checkpoints PyTorch
â”‚   â”œâ”€â”€ torchscript/     # Modelos TorchScript
â”‚   â””â”€â”€ onnx/            # Modelos ONNX
â”œâ”€â”€ datasets/            # Datasets de entrenamiento
â””â”€â”€ configs/             # Archivos de configuraciÃ³n
```

### ğŸ¯ Uso RÃ¡pido

#### Entrenamiento de Modelo

```python
from src.models.cnn_detector import CNNDetector
from src.utils.metrics import MetricsLogger

# Crear modelo
model = CNNDetector(input_channels=1, num_classes=2)

# Entrenar (tu cÃ³digo de entrenamiento existente)
# ...

# Generar mÃ©tricas automÃ¡ticamente
metrics_logger = MetricsLogger(model_name="CNN", save_dir="reports/plots")
metrics_logger.generate_all_plots(y_true, y_pred, y_scores, real_spec, fake_spec)
```

#### ExportaciÃ³n de Modelo

```python
# Congelar modelo para deployment
model.freeze()

# Exportar a todos los formatos
example_input = torch.randn(1, 128, 94)  # Ejemplo de input
paths = model.export_all(
    base_path="checkpoints",
    model_name="CNN_detector",
    example_input=example_input
)
# Genera: .pt, .ts, .onnx automÃ¡ticamente
```

#### EvaluaciÃ³n Adversarial (Opcional)

```python
from src.adversarial.adversarial_evaluator import AdversarialEvaluator

# Crear evaluador
evaluator = AdversarialEvaluator(
    model=model,
    model_name="CNN_detector",
    device='cuda'
)

# Evaluar robustez contra todos los ataques
results = evaluator.evaluate_all_attacks(test_loader)
# Genera reportes automÃ¡ticos en reports/adversarial/
```

#### Uso de Ataques Adversariales

```python
from src.adversarial.fgsm import fgsm_attack
from src.adversarial.pgd import PGD

# FGSM
adv_audio = fgsm_attack(model, waveform, label, epsilon=0.03)

# PGD
pgd = PGD(model, epsilon=0.03, alpha=0.01, num_iter=10)
adv_audio, metrics = pgd.generate(waveform, label)
```

---

## ğŸ“Š Datasets Recomendados

Los siguientes datasets pÃºblicos son recomendados para entrenar y evaluar DetectVoice:

### Datasets Principales

1. **ASVspoof 2019**
   Dataset estÃ¡ndar para detecciÃ³n de audio spoofing
   ğŸ”— https://www.asvspoof.org/index2019.html

2. **DSD-Corpus**
   Deepfake Speech Detection Corpus
   ğŸ”— https://zenodo.org/records/13788455

3. **LibriTTS**
   Multi-speaker English corpus
   ğŸ”— https://us.openslr.org/60/

4. **LibriTTS-R**
   Restored version of LibriTTS
   ğŸ”— https://www.openslr.org/141/

### Datasets Especializados

5. **AUDETER**
   Audio Deepfake Detection Dataset
   ğŸ”— https://arxiv.org/abs/2509.04345

6. **FoR Dataset**
   Fake or Real Dataset for Synthetic Speech Detection
   ğŸ”— https://cisaad.umbc.edu/for-fake-or-real-dataset-for-synthetic-speech-detection/

7. **DEEP-VOICE**
   Deepfake Voice Recognition Dataset
   ğŸ”— https://huggingface.co/datasets/DynamicSuperb/DeepFakeVoiceRecognition_DEEP-VOICE

8. **HAD (Half-Truth Audio Dataset)**
   Partially synthetic audio dataset
   ğŸ”— https://arxiv.org/abs/2104.03617

9. **ELAD-SVDSR**
   Enhanced Dataset for Synthetic Voice Detection
   ğŸ”— https://arxiv.org/abs/2510.00218

---

## ğŸ¨ MÃ©tricas y GrÃ¡ficos Generados AutomÃ¡ticamente

Cada entrenamiento genera automÃ¡ticamente:

- âœ… **Curva de PÃ©rdida** (loss_curve.png)
- âœ… **Curva de Accuracy** (accuracy_curve.png)
- âœ… **Curva ROC** (roc_curve.png)
- âœ… **Curva Precision-Recall** (precision_recall_curve.png)
- âœ… **Matriz de ConfusiÃ³n** (confusion_matrix.png)
- âœ… **ComparaciÃ³n Real vs Fake** (spectrogram_comparison.png)
- âœ… **Reporte de ClasificaciÃ³n** (classification_report.txt)
- âœ… **MÃ©tricas JSON** (metrics.json)

Todos los archivos se guardan en: `reports/plots/[modelo]/`

---

## ğŸ”¬ Mejoras del Sistema v2

### Nuevas Funcionalidades

1. **Sistema de ExportaciÃ³n Completo**
   - ExportaciÃ³n a PyTorch, TorchScript y ONNX
   - FunciÃ³n `freeze_model()` para deployment
   - ValidaciÃ³n automÃ¡tica de modelos exportados

2. **GeneraciÃ³n AutomÃ¡tica de MÃ©tricas**
   - 6 tipos de grÃ¡ficos generados automÃ¡ticamente
   - Reportes en JSON y texto
   - Comparaciones visuales de espectrogramas

3. **MÃ³dulo Adversarial Opcional**
   - Ataques: FGSM, PGD, C&W, DeepFool
   - No interfiere con entrenamiento regular
   - EvaluaciÃ³n de robustez completa

4. **Evaluador Adversarial**
   - Prueba automÃ¡tica de todos los ataques
   - Reportes detallados con grÃ¡ficos
   - ComparaciÃ³n de accuracy clean vs adversarial

5. **Compatibilidad Mejorada**
   - IntegraciÃ³n con cÃ³digo existente
   - Sin cambios en flujo de entrenamiento
   - Funciones opcionales y modulares

### Mejoras de CÃ³digo

- âœ… Tipado completo con type hints
- âœ… Logging profesional
- âœ… DocumentaciÃ³n completa
- âœ… Estructura modular y extensible
- âœ… Compatible con GPU/CPU

---

## âš ï¸ Disclaimer Legal y Ã‰tico

**Este proyecto tiene fines exclusivamente acadÃ©micos, cientÃ­ficos y de ciberseguridad defensiva.**

NingÃºn componente del repositorio debe utilizarse para generar deepfakes o para actividades que involucren suplantaciÃ³n, ingenierÃ­a social o prÃ¡cticas maliciosas.

**El uso indebido de este software es responsabilidad Ãºnica del usuario.**

### Usos Permitidos
- âœ… InvestigaciÃ³n acadÃ©mica en detecciÃ³n de deepfakes
- âœ… Desarrollo de sistemas de seguridad defensivos
- âœ… Pruebas de robustez de modelos
- âœ… AnÃ¡lisis forense de audio

### Usos Prohibidos
- âŒ GeneraciÃ³n de deepfakes maliciosos
- âŒ SuplantaciÃ³n de identidad
- âŒ Fraude o engaÃ±o
- âŒ ViolaciÃ³n de privacidad
- âŒ Cualquier uso ilegal o no Ã©tico

**Al usar este software, acepta cumplir con todas las leyes aplicables y utilizarlo Ãºnicamente para fines legÃ­timos y Ã©ticos.**

---

## ğŸ“¦ InstalaciÃ³n

```bash
# Clonar repositorio
git clone https://github.com/ethan1213/DetectVoice.git
cd DetectVoice

# Instalar dependencias
pip install -r requirements.txt
```

### Dependencias Principales

- Python 3.8+
- PyTorch >= 1.10
- TorchAudio
- NumPy, SciPy
- Matplotlib, Seaborn
- scikit-learn
- ONNX (para exportaciÃ³n)

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas siguiendo estos principios:

1. Enfoque en detecciÃ³n y seguridad defensiva
2. CÃ³digo bien documentado y testeado
3. Respeto a principios Ã©ticos
4. Compatibilidad con sistema existente

---

## ğŸ“ Licencia

Este proyecto estÃ¡ disponible para fines de investigaciÃ³n y educaciÃ³n. Ver LICENSE para mÃ¡s detalles.

---

## ğŸ“§ Contacto

Para preguntas sobre uso responsable o colaboraciones de investigaciÃ³n, abrir un issue en GitHub.

---

**Desarrollado con el objetivo de mejorar la seguridad y autenticidad del audio digital.**

**Uso responsable y Ã©tico Ãºnicamente. ğŸ”’**
