# ğŸ¤ DetectVoice v2.0: Advanced Audio Deepfake Detection Suite

<div align="center">

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.0+](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Estado del arte en detecciÃ³n de deepfakes de audio con arquitecturas mÃºltiples y robustez adversarial**

[CaracterÃ­sticas](#-caracterÃ­sticas) â€¢
[InstalaciÃ³n](#-instalaciÃ³n) â€¢
[Uso RÃ¡pido](#-uso-rÃ¡pido) â€¢
[Modelos](#-arquitecturas) â€¢
[Datasets](#-datasets) â€¢
[Disclaimer](#-disclaimer-legal)

</div>

---

## âš ï¸ DISCLAIMER LEGAL Y Ã‰TICO

### ğŸš¨ USO RESPONSABLE

**âœ… PERMITIDO:**
- ProtecciÃ³n contra fraudes y estafas
- InvestigaciÃ³n acadÃ©mica
- VerificaciÃ³n de autenticidad
- Desarrollo de seguridad
- AuditorÃ­a autorizada
- EducaciÃ³n en ML/cybersecurity

**âŒ PROHIBIDO:**
- Vigilancia no autorizada
- IdentificaciÃ³n sin consentimiento
- ViolaciÃ³n de privacidad
- DiscriminaciÃ³n
- Acoso o chantaje
- Uso ilegal

### ğŸ“œ Responsabilidades

El uso de este software implica aceptaciÃ³n de cumplir con GDPR, CCPA, y leyes locales de privacidad. Los usuarios son TOTALMENTE RESPONSABLES del uso legal y Ã©tico. Los autores NO son responsables de mal uso.

---

## ğŸ¯ CaracterÃ­sticas Principales

### ğŸ—ï¸ 25+ Modelos Implementados

- **Transformers**: Wav2Vec2, HuBERT, AST
- **ClÃ¡sicos**: SVM, XGBoost, Random Forest, Logistic Regression
- **Deep Learning**: CNN 1D/2D, LSTM, BiLSTM, GRU, BiGRU, CRNN
- **Avanzados**: ECAPA-TDNN, ResNet-Audio, QuartzNet, Conformer, Harmonic CNN
- **Generativos**: Autoencoders, VAE, Siamese Networks, GAN Discriminators

### ğŸ¼ ExtracciÃ³n de CaracterÃ­sticas

- MFCC, Mel Spectrogram, STFT, Chroma, CQT
- Spectral features, Zero Crossing Rate
- Pitch & Formant tracking
- Raw waveform support

### ğŸ”„ Data Augmentation

- Noise injection (white/pink/brown)
- Time stretching, Pitch shifting
- Codec simulation, Room acoustics
- SpecAugment

### ğŸ¯ Sistema de Ensamblado

- Simple/Weighted Averaging
- Voting (hard/soft)
- Stacking con meta-modelo
- Jury System (N-model agreement)

### ğŸ“Š Tracking & VisualizaciÃ³n

- TensorBoard & MLflow integration
- ROC, PR, DET curves
- Confusion matrices
- t-SNE/UMAP embeddings
- Feature importance

---

## ğŸ“¦ InstalaciÃ³n

```bash
# Clonar
git clone https://github.com/ethan1213/DetectVoice.git
cd DetectVoice

# OpciÃ³n 1: pip
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# OpciÃ³n 2: conda
conda env create -f environment.yaml
conda activate detectvoice
```

---

## ğŸš€ Uso RÃ¡pido

### Inferencia

```python
from src.inference.inference_engine import InferenceEngine
from src.models.transformers import Wav2Vec2Detector

model = Wav2Vec2Detector()
engine = InferenceEngine(model, {'sample_rate': 16000}, device='cuda')

result = engine.predict_single('test.wav')
print(f"PredicciÃ³n: {result['prediction']} (confianza: {result['confidence']:.2%})")
```

### Entrenamiento

```python
from src.training.train_master import MasterTrainer
from src.models.advanced import ECAPATDNNDetector

model = ECAPATDNNDetector()
trainer = MasterTrainer(model, config, device='cuda')
trainer.train(train_loader, val_loader, epochs=50)
```

---

## ğŸ›ï¸ Arquitecturas Implementadas

| CategorÃ­a | Modelos | Papers |
|-----------|---------|--------|
| **Transformers** | Wav2Vec2, HuBERT, AST | Baevski+ 2020, Hsu+ 2021, Gong+ 2021 |
| **Avanzados** | ECAPA-TDNN, ResNet, QuartzNet, Conformer, Harmonic CNN | Desplanques+ 2020, He+ 2015, etc. |
| **Deep Learning** | CNN 1D/2D, LSTM, BiLSTM, GRU, BiGRU, CRNN | Standard architectures |
| **ClÃ¡sicos** | SVM, XGBoost, RF, LogReg | Standard ML |

---

## ğŸ“š Datasets Soportados

### Deepfake
- ASVspoof 2019 & 2021
- FakeAVCeleb, WaveFake
- FoR, ADD 2022
- AUDETER, DSD-Corpus

### Real Voice
- LibriSpeech, LibriTTS-R
- Mozilla Common Voice
- VoxCeleb 1 & 2

### Scripts de Descarga

```bash
python src/utils/download_datasets.py
```

---

## ğŸ› ï¸ Estructura del Proyecto

```
DetectVoice/
â”œâ”€â”€ configs/config.yaml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ transformers/
â”‚   â”‚   â”œâ”€â”€ classical/
â”‚   â”‚   â”œâ”€â”€ deep_learning/
â”‚   â”‚   â”œâ”€â”€ advanced/
â”‚   â”‚   â””â”€â”€ ensemble/
â”‚   â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ visualization/
â”‚   â”œâ”€â”€ inference/
â”‚   â””â”€â”€ utils/
â”œâ”€â”€ data/
â”œâ”€â”€ outputs/
â””â”€â”€ weights/
```

---

## ğŸ“„ Licencia

MIT License con restricciones Ã©ticas. Ver LICENSE para detalles.

---

## ğŸ™ Referencias

```bibtex
@inproceedings{baevski2020wav2vec,
  title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
  author={Baevski, Alexei and others},
  booktitle={NeurIPS},
  year={2020}
}
```

---

<div align="center">

**âš–ï¸ USE CON RESPONSABILIDAD | Desarrollado para combatir deepfakes**

</div>
